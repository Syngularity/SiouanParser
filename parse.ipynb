{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charles\\NLP\n",
      "\u001b[1m\u001b[92m  ______ _                          \n",
      " / _____|_)                         \n",
      "( (____  _  ___  _   _ _____ ____   \n",
      " \\____ \\| |/ _ \\| | | (____ |  _ \\  \n",
      " _____) ) | |_| | |_| / ___ | | | | \n",
      "(______/|_|\\___/|____/\\_____|_| |_| \n",
      "                                    \n",
      " ______                             \n",
      "(_____ \\                            \n",
      " _____) )____  ____ ___ _____  ____ \n",
      "|  ____(____ |/ ___)___) ___ |/ ___)\n",
      "| |    / ___ | |  |___ | ____| |    \n",
      "|_|    \\_____|_|  (___/|_____)_|    \n",
      "\u001b[95mv0.01\u001b[0m \n",
      "\n",
      "Parsing Source <sources> directory...\n",
      "Processed: bible.txt\n",
      "1 File(s) Processed.\n",
      "\n",
      "Complete!\n",
      "\u001b[1m\n",
      "Top 100 Frequency Distribution\n",
      "\t1. kin (50567 times) (6.88%)\n",
      "\u001b[91m \t\t> High Frequency: Possible Stop Word!\u001b[0m\u001b[1m\n",
      "\t2. qa (37410 times) (5.09%)\n",
      "\u001b[91m \t\t> High Frequency: Possible Stop Word!\u001b[0m\u001b[1m\n",
      "\t3. kta (21102 times) (2.87%)\n",
      "\u001b[91m \t\t> High Frequency: Possible Stop Word!\u001b[0m\u001b[1m\n",
      "\t4. he (19074 times) (2.6%)\n",
      "\u001b[91m \t\t> High Frequency: Possible Stop Word!\u001b[0m\u001b[1m\n",
      "\t5. unkan (11392 times) (1.55%)\n",
      "\u001b[91m \t\t> High Frequency: Possible Stop Word!\u001b[0m\u001b[1m\n",
      "\t6. en (10721 times) (1.46%)\n",
      "\u001b[91m \t\t> High Frequency: Possible Stop Word!\u001b[0m\u001b[1m\n",
      "\t7. śni (10132 times) (1.38%)\n",
      "\u001b[91m \t\t> High Frequency: Possible Stop Word!\u001b[0m\u001b[1m\n",
      "\t8. on (8699 times) (1.18%)\n",
      "\u001b[91m \t\t> High Frequency: Possible Stop Word!\u001b[0m\u001b[1m\n",
      "\t9. cin (8257 times) (1.12%)\n",
      "\u001b[91m \t\t> High Frequency: Possible Stop Word!\u001b[0m\u001b[1m\n",
      "\t10. hena (7206 times) (0.98%)\n",
      "\t11. taku (6400 times) (0.87%)\n",
      "\t12. jehowa (6126 times) (0.83%)\n",
      "\t13. | (6058 times) (0.82%)\n",
      "\t14. etanhan (5838 times) (0.79%)\n",
      "\t15. kte (5637 times) (0.77%)\n",
      "\t16. wan (5188 times) (0.71%)\n",
      "\t17. wicasta (4813 times) (0.66%)\n",
      "\t18. ekta (4698 times) (0.64%)\n",
      "\t19. tuka (4654 times) (0.63%)\n",
      "\t20. owasin (4611 times) (0.63%)\n",
      "\t21. iye (4506 times) (0.61%)\n",
      "\t22. wo (3851 times) (0.52%)\n",
      "\t23. hecen (3509 times) (0.48%)\n",
      "\t24. ce (3252 times) (0.44%)\n",
      "\t25. ohna (3071 times) (0.42%)\n",
      "\t26. un (3039 times) (0.41%)\n",
      "\t27. heon (3012 times) (0.41%)\n",
      "\t28. hehan (2942 times) (0.4%)\n",
      "\t29. wakan (2898 times) (0.39%)\n",
      "\t30. tuwe (2667 times) (0.36%)\n",
      "\t31. tawa (2655 times) (0.36%)\n",
      "\t32. cinca (2630 times) (0.36%)\n",
      "\t33. eya (2529 times) (0.34%)\n",
      "\t34. anpetu (2523 times) (0.34%)\n",
      "\t35. e (2519 times) (0.34%)\n",
      "\t36. oyate (2513 times) (0.34%)\n",
      "\t37. israel (2421 times) (0.33%)\n",
      "\t38. nakun (2420 times) (0.33%)\n",
      "\t39. pi (2408 times) (0.33%)\n",
      "\t40. wi (2367 times) (0.32%)\n",
      "\t41. na (2362 times) (0.32%)\n",
      "\t42. tona (2325 times) (0.32%)\n",
      "\t43. wa (2306 times) (0.31%)\n",
      "\t44. han (2306 times) (0.31%)\n",
      "\t45. ece (2282 times) (0.31%)\n",
      "\t46. qon (2247 times) (0.31%)\n",
      "\t47. ye (2166 times) (0.29%)\n",
      "\t48. ca (2152 times) (0.29%)\n",
      "\t49. kinhan (2069 times) (0.28%)\n",
      "\t50. wakantanka (2068 times) (0.28%)\n",
      "\t51. po (2053 times) (0.28%)\n",
      "\t52. de (1986 times) (0.27%)\n",
      "\t53. akan (1960 times) (0.27%)\n",
      "\t54. tipi (1939 times) (0.26%)\n",
      "\t55. yapi (1917 times) (0.26%)\n",
      "\t56. makoce (1892 times) (0.26%)\n",
      "\t57. itancan (1844 times) (0.25%)\n",
      "\t58. wicowoyake (1836 times) (0.25%)\n",
      "\t59. iyecen (1834 times) (0.25%)\n",
      "\t60. ya (1829 times) (0.25%)\n",
      "\t61. ga (1771 times) (0.24%)\n",
      "\t62. niye (1723 times) (0.23%)\n",
      "\t63. i (1690 times) (0.23%)\n",
      "\t64. ça (1688 times) (0.23%)\n",
      "\t65. miye (1595 times) (0.22%)\n",
      "\t66. tanka (1578 times) (0.21%)\n",
      "\t67. hee (1498 times) (0.2%)\n",
      "\t68. waste (1441 times) (0.2%)\n",
      "\t69. cinhintku (1376 times) (0.19%)\n",
      "\t70. maka (1364 times) (0.19%)\n",
      "\t71. wica (1343 times) (0.18%)\n",
      "\t72. nape (1308 times) (0.18%)\n",
      "\t73. can (1288 times) (0.18%)\n",
      "\t74. ni (1279 times) (0.17%)\n",
      "\t75. ta (1258 times) (0.17%)\n",
      "\t76. heya (1257 times) (0.17%)\n",
      "\t77. otonwe (1245 times) (0.17%)\n",
      "\t78. wicaśta (1244 times) (0.17%)\n",
      "\t79. heciya (1243 times) (0.17%)\n",
      "\t80. kici (1240 times) (0.17%)\n",
      "\t81. econ (1194 times) (0.16%)\n",
      "\t82. wikcemna (1144 times) (0.16%)\n",
      "\t83. iyececa (1142 times) (0.16%)\n",
      "\t84. juda (1131 times) (0.15%)\n",
      "\t85. sanpa (1124 times) (0.15%)\n",
      "\t86. itokam (1103 times) (0.15%)\n",
      "\t87. yatapi (1089 times) (0.15%)\n",
      "\t88. wanji (1088 times) (0.15%)\n",
      "\t89. ti (1086 times) (0.15%)\n",
      "\t90. nonpa (1074 times) (0.15%)\n",
      "\t91. dawid (1063 times) (0.14%)\n",
      "\t92. tokeca (1055 times) (0.14%)\n",
      "\t93. nitawa (1054 times) (0.14%)\n",
      "\t94. jesus (1054 times) (0.14%)\n",
      "\t95. ka (1040 times) (0.14%)\n",
      "\t96. ko (965 times) (0.13%)\n",
      "\t97. sni (965 times) (0.13%)\n",
      "\t98. pa (963 times) (0.13%)\n",
      "\t99. unpi (951 times) (0.13%)\n",
      "\t100. u (913 times) (0.12%)\n",
      "\u001b[0m\n",
      "\n",
      "Stop Characters used: (,.;?\\-:)\n",
      "Stop Word Frequency Detection Threshold: 1%\n",
      "734468 Tokens Generated.\n"
     ]
    }
   ],
   "source": [
    "# Language Processing Script\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "import itertools\n",
    "import threading\n",
    "import time\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "##############################################\n",
    "#\n",
    "# Important Variables!\n",
    "#\n",
    "##############################################\n",
    "#Auto high frequency detection value (%)\n",
    "stopFreq = 1\n",
    "\n",
    "#Stop Characters ignored in sources\n",
    "stopChars = \"(,.;?\\-:)\"\n",
    "\n",
    "sourceDir = \"sources\"\n",
    "\n",
    "#First run - Install NLTK Dependancy\n",
    "firstRun = False\n",
    "\n",
    "##############################################\n",
    "\n",
    "\n",
    "source = \"\"\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(sourceDir)\n",
    "    \n",
    "#Loading - it might take awhile!\n",
    "done = False\n",
    "def animate():\n",
    "    for c in itertools.cycle(['|', '/', '-', '\\\\']):\n",
    "        if done:\n",
    "            break\n",
    "        sys.stdout.write('\\rParsing ' + c)\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(0.1)\n",
    "    sys.stdout.write('\\rComplete!\\n')\n",
    "\n",
    "if firstRun:\n",
    "    nltk.download('punkt')\n",
    "    print(\"Re-run now with first run turned off!\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "print (\"\\033[1m\\033[92m  ______ _                          \")\n",
    "print (\" / _____|_)                         \")\n",
    "print (\"( (____  _  ___  _   _ _____ ____   \")\n",
    "print (\" \\____ \\| |/ _ \\| | | (____ |  _ \\  \")\n",
    "print (\" _____) ) | |_| | |_| / ___ | | | | \")\n",
    "print (\"(______/|_|\\___/|____/\\_____|_| |_| \")\n",
    "print (\"                                    \")\n",
    "print (\" ______                             \")\n",
    "print (\"(_____ \\                            \")\n",
    "print (\" _____) )____  ____ ___ _____  ____ \")\n",
    "print (\"|  ____(____ |/ ___)___) ___ |/ ___)\")\n",
    "print (\"| |    / ___ | |  |___ | ____| |    \")\n",
    "print (\"|_|    \\_____|_|  (___/|_____)_|    \")\n",
    "print (\"\\033[95mv0.01\\033[0m \\n\")\n",
    "\n",
    "\n",
    "\n",
    "#Join all sources files found within source directory into 'source'\n",
    "print (\"Parsing Source <\" + sourceDir + \"> directory...\")\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "    with open(os.path.join(os.getcwd(), filename), encoding=\"utf8\") as f:\n",
    "        source = source + f.read()\n",
    "        print (\"Processed: \" + filename)\n",
    "print (str(len(os.listdir(os.getcwd()))) + \" File(s) Processed.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#Load Stopwords\n",
    "os.chdir(\"../\")\n",
    "\n",
    "#with open(os.getcwd() + '\\\\stopwords.txt') as f:\n",
    "#    stopwords = f.read().splitlines()\n",
    "\n",
    "t = threading.Thread(target=animate)\n",
    "t.start()\n",
    "\n",
    "#Clean up input\n",
    "parsed = ''.join([i for i in source if not i.isdigit()]) #Remove numbers\n",
    "parsed = parsed.replace('\\n', ' ').replace('\\r', '') #Remove newline\n",
    "parsed = re.sub(' +', ' ', parsed) #Remove extra spaces\n",
    "parsed = re.sub('[' + stopChars + ']', '', parsed) #Remove stop characters\n",
    "parsed = parsed.lower() #Set to all lowercase\n",
    "\n",
    "#Begin NLTK Processing\n",
    "tokens = word_tokenize(parsed)\n",
    "fdist = FreqDist(tokens)\n",
    "\n",
    "done = True\n",
    "time.sleep(0.1)\n",
    "print ('\\033[1m')\n",
    "print(\"Top 100 Frequency Distribution\")\n",
    "\n",
    "for i in enumerate(fdist.most_common(100)): \n",
    "    print(\"\\t\" + str(i[0]+1) + \". \" + i[1][0] + \" (\" + str(i[1][1]) + \" times) (\" + str(round(fdist.freq(i[1][0])*100,2)) + \"%)\")\n",
    "    if round(fdist.freq(i[1][0])*100,2) > stopFreq:\n",
    "        print (\"\\033[91m \\t\\t> High Frequency: Possible Stop Word!\\033[0m\\033[1m\")\n",
    "\n",
    "print ('\\033[0m')\n",
    "\n",
    "print(\"\\nStop Characters used: \" + stopChars)\n",
    "print(\"Stop Word Frequency Detection Threshold: \" + str(stopFreq) + \"%\")\n",
    "print(str(len(tokens)) + \" Tokens Generated.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
